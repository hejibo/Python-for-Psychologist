{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Eye Movement Animations\n",
      "\n",
      "Here we illustrate a cute, but perhaps not so scientifically useful, animated gaze position overlay cursor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from executeNotebook import execute_notebook\n",
      "execute_notebook(\"Py4ET_2013_ECEM_Workshop.ipynb\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRIAL_ID=1\n",
      "\n",
      "# For binocular recording 0 = Left eye, 1 = Right eye. Monocular recording should always use 0.\n",
      "#\n",
      "EYE_INDEX=0\n",
      "\n",
      "et_sampling_rate=ET_WORKBOOK_INFO['sampling_rate']\n",
      "\n",
      "# in msec, so 1000/desired_playback_rate ~= desired frame rate in Hz.\n",
      "#\n",
      "desired_playback_rate=20\n",
      "\n",
      "#####\n",
      "\n",
      "# Select the ioDataStore hdf5 file to process.\n",
      "# and load specified event type and event attribute values.\n",
      "#\n",
      "results_by_trial=loadSampleData(ET_WORKBOOK_INFO['event_type'],\n",
      "                                         ET_WORKBOOK_INFO['event_fields'])\n",
      "\n",
      "trial_data=results_by_trial[TRIAL_ID]\n",
      "\n",
      "#### Filling Gaps in Data Stream\n",
      "#**What!:**\n",
      "#\n",
      "#- Gap Filling is performed because:\n",
      "#    1. many filtering algormithms require evenly spaced data points temporally\n",
      "#    2. reduces / removes filter artifacts that would otherwise exist at the boundaries of discontinuities\n",
      "#- **Filled Gap Data is removed again after data filtering / processing, prior to analysis / plotting.**\n",
      "#\n",
      "gaze_field_groups=ET_WORKBOOK_INFO['gaze_fields']\n",
      "pupil_size_fields=ET_WORKBOOK_INFO['pupil_size_fields']\n",
      "\n",
      "gaze_fields=gaze_field_groups[EYE_INDEX]\n",
      "pupil_size_field=pupil_size_fields[EYE_INDEX]\n",
      "\n",
      "invalid_data_mask=None\n",
      "if EYE_TRACKER_USED=='SRR':\n",
      "    invalid_data_mask=getattr(trial_data,pupil_size_fields[EYE_INDEX])==0   \n",
      "elif EYE_TRACKER_USED=='TOBII':\n",
      "    invalid_data_mask=trial_data.status//10>=2\n",
      "\n",
      "time=trial_data.time\n",
      "xpix=getattr(trial_data,gaze_fields[0]).copy()\n",
      "ypix=getattr(trial_data,gaze_fields[1]).copy()\n",
      "pupil_trace=getattr(trial_data,pupil_size_field).copy()\n",
      "valid_data_periods=processSampleEventGaps(xpix,ypix,pupil_trace,invalid_data_mask,'clear')\n",
      "\n",
      "# get the trial condition values used for each trial in example experiment.\n",
      "#\n",
      "condition_set=trial_data.condition_set\n",
      "    \n",
      "# Get the image name used for display during the trial\n",
      "#\n",
      "image_name=condition_set.IMAGE_NAME\n",
      "trial_id=condition_set.trial_id\n",
      "# load the image\n",
      "#\n",
      "trial_image_array=numpy.flipud(mpimg.imread(\"./images/\"+image_name))\n",
      "\n",
      "# Get background image size\n",
      "image_size=(trial_image_array.shape[1],trial_image_array.shape[0])\n",
      "ihw,ihh=image_size[0]/2,image_size[1]/2\n",
      "\n",
      "dpi = 80\n",
      "margin = 0.05 # (5% of the width/height of the figure...)\n",
      "xpixels, ypixels = image_size\n",
      "\n",
      "# Make a figure big enough to accomodate an axis of xpixels by ypixels\n",
      "# as well as the ticklabels, etc...\n",
      "figsize = (1 + margin) * xpixels / dpi, (1 + margin) * ypixels / dpi\n",
      "\n",
      "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
      "# Make the axis the right size...\n",
      "ax = fig.add_axes([margin, margin, 1 - 2*margin, 1 - 2*margin])\n",
      "\n",
      "circle = plt.Circle((1000, 1000), radius=12, facecolor='r',edgecolor='y', linewidth=2, alpha=0.7)\n",
      "time_text = ax.text(0.02, 0.95, '', color='black', fontsize=15, bbox={'facecolor':'red', 'alpha':0.5, 'pad':10},transform=ax.transAxes)\n",
      "\n",
      "ax.imshow(trial_image_array,origin='lower',extent=(-ihw, ihw,-ihh, ihh))\n",
      "\n",
      "plt.title(\"Trial {0}: {1}\".format(trial_id,image_name))\n",
      "\n",
      "ifi=1000.0/et_sampling_rate\n",
      "sample_frame_interval=desired_playback_rate//ifi+1\n",
      "actual_playback_rate=int(sample_frame_interval*ifi)\n",
      "\n",
      "sample_frame_count=int(len(time)//sample_frame_interval)\n",
      "\n",
      "def init():\n",
      "    ax.add_patch(circle)\n",
      "    time_text.set_text('time = %.1f sec' % time[0])\n",
      "    return circle,time_text\n",
      "\n",
      "def animate(i):\n",
      "    s=int(i*sample_frame_interval)\n",
      "    circle.center = (xpix[s], ypix[s])\n",
      "    time_text.set_text('time = %.1f sec' % time[s])\n",
      "    return circle,time_text\n",
      "\n",
      "anim = animation.FuncAnimation(fig, animate, \n",
      "                               init_func=init, \n",
      "                               frames=1, \n",
      "                               interval=actual_playback_rate,\n",
      "                               blit=False)\n",
      "\n",
      "anim = animation.FuncAnimation(fig, animate, \n",
      "                               init_func=init, \n",
      "                               frames=sample_frame_count, \n",
      "                               interval=actual_playback_rate,\n",
      "                               blit=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Saving the Animation as a Video (and Displaying Video in a notebook after creation)\n",
      "\n",
      "This seems possible based on demo's and reports I have found on the web, but I could not get it to work. Perhaps some issue with my env. setup??\n",
      "\n",
      "If you want to give it a try, here is a link showing inline animation plots:\n",
      "\n",
      "[http://nickcharlton.net/posts/drawing-animating-shapes-matplotlib.html](http://nickcharlton.net/posts/drawing-animating-shapes-matplotlib.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://nickcharlton.net/posts/drawing-animating-shapes-matplotlib.html width=700 height=450></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://nickcharlton.net/posts/drawing-animating-shapes-matplotlib.html width=700 height=450></iframe>"
       ],
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<IPython.core.display.HTML at 0x8d7a6b0>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}