{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ECEM Py4ET 2013 Workshop Example Code Eye Tracker and Data Set Constants.\n",
      "### Modify as needed for the Eye Tracker type used during data collection."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# psychopy.iohub related imports.....\n",
      "#\n",
      "import psychopy.iohub\n",
      "from psychopy.iohub import EventConstants,DeviceConstants,module_directory,Computer\n",
      "from psychopy.iohub.datastore.util import displayDataFileSelectionDialog, ExperimentDataAccessUtility\n",
      "\n",
      "# Mappings between ET Used and known fixed settings for workbook\n",
      "et_workbook_info=dict(LC_TECH={},SMI={},SRR={},TOBII={})\n",
      "\n",
      "# User set constants to use throughout workbook...\n",
      "#\n",
      "et_workbook_info['SRR'].update(\n",
      "                            sampling_rate=1000.0,\n",
      "                            event_type=EventConstants.MONOCULAR_EYE_SAMPLE,\n",
      "                            event_fields=['time','gaze_x','gaze_y','pupil_measure1','status'],\n",
      "                            pupil_size_fields=['pupil_measure1',],\n",
      "                            gaze_fields=[['gaze_x','gaze_y'],],\n",
      "                            calibration_area_info=dict(display_size_mm=(500,280.0),\n",
      "                                                       display_res_pix=(1280.0,1024.0),\n",
      "                                                       eye_distance_mm=550.0)\n",
      "                            )\n",
      "et_workbook_info['TOBII'].update(\n",
      "                            sampling_rate=120.0,\n",
      "                            event_type=EventConstants.BINOCULAR_EYE_SAMPLE,\n",
      "                            event_fields=['time','left_gaze_x','left_gaze_y','left_pupil_measure1',\n",
      "                                          'right_gaze_x','right_gaze_y','right_pupil_measure1','status'],\n",
      "                            pupil_size_fields=['left_pupil_measure1','right_pupil_measure1'],\n",
      "                            gaze_fields=[['left_gaze_x','left_gaze_y'],['right_gaze_x','right_gaze_y']],\n",
      "                            calibration_area_info=dict(display_size_mm=(500.0,300.0),\n",
      "                                                       display_res_pix=(1280.0,1024.0),\n",
      "                                                       eye_distance_mm=650.0)\n",
      "                            )\n",
      "\n",
      "EYE_TRACKER_USED='TOBII'\n",
      "ET_WORKBOOK_INFO=et_workbook_info[EYE_TRACKER_USED]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Python Module / Package Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# core module imports\n",
      "#\n",
      "import os\n",
      "import sys\n",
      "\n",
      "# Matplotlib imports\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.pylab as plb\n",
      "import matplotlib.transforms as mtransforms\n",
      "import matplotlib.image as mpimg\n",
      "from matplotlib.collections import LineCollection\n",
      "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
      "import matplotlib.cm as cm\n",
      "from matplotlib import animation\n",
      "\n",
      "# Scipy / Numpy imports\n",
      "#\n",
      "import scipy.signal\n",
      "import scipy.stats\n",
      "from scipy.ndimage.filters import gaussian_filter1d\n",
      "import numpy as np\n",
      "\n",
      "# iPython\n",
      "#\n",
      "from IPython.display import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Common Functions Used in the Example Code Created for the ECEM Py4ET 2013 Workshop"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## def loadSampleData(event_type,retrieve_attributes)\n",
      "\n",
      "Open a file chooser dialog to select an ioHub DataStore hdf5 file for use in data processing, visuualization, or analysis.\n",
      "\n",
      "###Parameters\n",
      "\n",
      "**event_type :** int\n",
      "\n",
      "- One of the ioHub device event type constants found in psychopy.iohub.EventsConstants.\n",
      "\n",
      "**retrieve_attributes :** array or list of str\n",
      "\n",
      "- The list of event attributes / fields that would be retrieved from the event table associated with the event_type param provided.\n",
      "\n",
      "###Returns\n",
      "\n",
      "**session_event_data :** list\n",
      "\n",
      "- "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadSampleData(event_type,retrieve_attributes):\n",
      "    # Open an ioDataStore HDF5 file.\n",
      "    #\n",
      "    data_file_path= displayDataFileSelectionDialog(psychopy.iohub.module_directory(execute_notebook))  \n",
      "    if data_file_path is None:\n",
      "        sys.exit(0)\n",
      "    dpath,dfile=os.path.split(data_file_path)           \n",
      "\n",
      "    # Create an instance of the ExperimentDataAccessUtility class\n",
      "    # for the selected DataStore file. This allows us to access data\n",
      "    # in the file based on Device Event names and attributes.\n",
      "    #\n",
      "    dataAccessUtil=ExperimentDataAccessUtility(dpath,dfile, experimentCode=None,sessionCodes=[])\n",
      "    \n",
      "    # Retrieve a subset of the BINOCULAR_EYE_SAMPLE event attributes, for events that occurred\n",
      "    # between each time period defined by the TRIAL_START and TRIAL_END trial variables of each entry\n",
      "    # in the trial_conditions data table.\n",
      "    #\n",
      "    session_event_data=dataAccessUtil.getEventAttributeValues(event_type,\n",
      "                                retrieve_attributes,\n",
      "                                conditionVariablesFilter=None, \n",
      "                                startConditions={'time':('>=','@TRIAL_START@')},\n",
      "                                endConditions={'time':('<=','@TRIAL_END@')})\n",
      "    \n",
      "    \n",
      "    dataAccessUtil.close()\n",
      "    return session_event_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## processSampleEventGaps(x,y,pupil,missing_points_marray,gap_fill_operation='clear')\n",
      "\n",
      "Performs the requested fill operation on areas of the x,y and pupil size arrays that \n",
      "are specified by missing_points_marray masked array. Supported fill operations are \n",
      "'clear', and 'linear'. \n",
      "\n",
      "x, y, and pupil arrays must be of equal length, with each element of the different arrays representing the sample\n",
      "value for the same time during data collection.\n",
      "\n",
      "###Parameters\n",
      "\n",
      "**x :** numpy array like object\n",
      "\n",
      "-  Array shape must be Nx1, where N is the number of x position readings in the data list.\n",
      "\n",
      "**y :** numpy array like object\n",
      "\n",
      "-  Array shape must be Nx1, where N is the number of y position readings in the data list.\n",
      "\n",
      "**pupil :** numpy array like object\n",
      "\n",
      "-  Array shape must be Nx1, where N is the number of pupil size readings in the data list.\n",
      "\n",
      "**missing_points_marray :** numpy masked array\n",
      "\n",
      "- A masked array of shape Nx1, where N == the length of the x,y,pupil array. Each element of the array indicates if the\n",
      "associated data array elemnt should be considered as a missing value reading, or a valid data point.\n",
      "\n",
      "**gap_fill_operation :** either 'clear' or 'linear'\n",
      "\n",
      "- Indicates how missing value periods within the x,y, and pupil data arrays should be filled. \n",
      "\n",
      "    - 'clear': Set missing data elements with numpy.NaN for x,y arrays and 0 for the pupil size array.\n",
      "    - 'linear': Set each missing data regions, Mi:Mj, within the x and y arrays to be linearly interpelated between the values of element i-1 and j of the array. pupil size array elements are set to 0.\n",
      "  \n",
      "\n",
      "###Returns\n",
      "\n",
      "**valid_data_periods :** list of array slices\n",
      "\n",
      "- Returns the list of array slices that specify the array regions in x,y, and pupil that should be considered valid data periods that have note been cleared or created using linear interpolation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def processSampleEventGaps(x,y,pupil,missing_points_marray,gap_fill_operation='clear'):\n",
      "    valid_data_periods=np.ma.extras.notmasked_contiguous(\n",
      "                                np.ma.array(pupil, mask=missing_points_marray)\n",
      "                                )                                \n",
      "    if gap_fill_operation == 'linear':\n",
      "        # Linear fill in for data processing / filtering continuity\n",
      "        #\n",
      "        fill_in_data_arrays=[x,y]           \n",
      "        for data_array in fill_in_data_arrays:        \n",
      "            data_array[0:valid_data_periods[0].start]=data_array[valid_data_periods[0].start]\n",
      "            last_slice_end=valid_data_periods[0].stop\n",
      "            for data_slice in valid_data_periods[1:]:\n",
      "                invalid_1=last_slice_end\n",
      "                invalid_2=data_slice.start\n",
      "                valcount=(invalid_2-invalid_1)\n",
      "                # fill\n",
      "                startval=data_array[invalid_1-1]\n",
      "                endval=data_array[invalid_2]\n",
      "                last_slice_end=data_slice.stop\n",
      "                #display(\"{}:{}, {}:{}, {}, {}\".format(invalid_1,invalid_2,startval,endval,valcount,(endval-startval)/valcount))\n",
      "                if endval==startval:\n",
      "                    data_array[invalid_1:invalid_2]=endval\n",
      "                else:\n",
      "                    data_array[invalid_1:invalid_2]=np.arange(startval,endval,(endval-startval)/valcount)[0:valcount]\n",
      "        pupil[missing_points_marray]=0\n",
      "    elif gap_fill_operation=='clear':\n",
      "        fill_in_data_arrays=[x,y]           \n",
      "        for data_array in fill_in_data_arrays:        \n",
      "            data_array[missing_points_marray]=np.NaN\n",
      "        pupil[missing_points_marray]=0        \n",
      "    return valid_data_periods"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#VisualAngleCalc Class\n",
      "\n",
      "Used to store calibrated area information and eye distance to screen data so that pixel data values can be converted to visual degree values.\n",
      "\n",
      "The pix2deg method is vectorized, meaning that is will perform the pixel to angle calculations on all elements of the provided pixel position numpy arrays in one numpy call. The convertion process can use either a fixed eye to calibration plane distance, or a numpy array of eye distances equal in length to the display_pos_x,display_pos_y (optional) pixel position data array.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class VisualAngleCalc(object):\n",
      "    def __init__(self,display_size_mm,display_res_pix,eye_distance_mm=None):\n",
      "        self._display_width=display_size_mm[0]\n",
      "        self._display_height=display_size_mm[1]\n",
      "        self._display_x_resolution=display_res_pix[0]\n",
      "        self._display_y_resolution=display_res_pix[1]\n",
      "        self._eye_distance_mm=eye_distance_mm\n",
      "        \n",
      "    def pix2deg(self,display_pos_x,display_pos_y=None,display_dim_x=None,display_dim_y=None,eye_distance_mm=None):\n",
      "        \"\"\"\n",
      "        Stimulus positions (display_pos_x,display_pos_y) are defined in x and y pixel units, with the origin (0,0)\n",
      "        being at the **center** of the display, as to match the PsychoPy pix unit coord type.\n",
      "    \n",
      "        Stimulus dimentions (display_dim_x,display_dim_y) are defined in pixels, representing the width, height of\n",
      "        the stim area, with stim_xy being the origin. stim_dim_xy is optional.\n",
      "    \n",
      "        For example, a stim with a width,height of 100,100 pixels, centered on display pixel\n",
      "        localation 200,200 (where 0,0 is the display center), would have:\n",
      "            display_pos_xy=150,150\n",
      "            display_dim_xy=100,100\n",
      "        \"\"\"\n",
      "        if self._eye_distance_mm is None and eye_distance_mm is None:\n",
      "            raise ValueError(\"The eye_distance_mm arguement must not be None as no default eye distance was provided for VisualAngleCalc.\")\n",
      "        eye_dist_mm=self._eye_distance_mm\n",
      "        if eye_distance_mm is not None:\n",
      "            eye_dist_mm=eye_distance_mm\n",
      "            \n",
      "        sx,sy=display_pos_x,display_pos_y\n",
      "        \n",
      "        thetaH1=np.degrees(np.arctan(sx/(eye_dist_mm*self._display_x_resolution/self._display_width)))\n",
      "        \n",
      "        if sy is not None:\n",
      "            thetaV1=np.degrees(np.arctan(sy/(eye_dist_mm*self._display_y_resolution/self._display_height)))\n",
      "\n",
      "        if display_dim_x:\n",
      "            sw,sh=display_dim_x,display_dim_y\n",
      "            thetaH2=np.degrees(np.arctan(((sw+sx)/(eye_dist_mm*self._display_x_resolution/self._display_width))))\n",
      "            horz_degree_dist=thetaH2-thetaH1\n",
      "            if display_dim_y:\n",
      "                thetaV2=np.degrees(np.arctan(((sh+sy)/(eye_dist_mm*self._display_y_resolution/self._display_height))))\n",
      "                vert_degree_dist=thetaV2-thetaV1\n",
      "        \n",
      "        if sy is not None:\n",
      "            if display_dim_y:\n",
      "                return (thetaH1,thetaV1),(horz_degree_dist,vert_degree_dist)\n",
      "            else:\n",
      "                return thetaH1,thetaV1\n",
      "        else:\n",
      "            if display_dim_x:\n",
      "                return thetaH1,horz_degree_dist\n",
      "            else:\n",
      "                return thetaH1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# calculateVelocity(time,data_x,data_y=None,units='deg')\n",
      "\n",
      "Calculate the instantanious velocity for data points in data_x and (optionally) data_y, using the time array for time delta information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculateVelocity(time,data_x,data_y=None,units='deg'):\n",
      "    \"\"\"\n",
      "    Returns data in visual degrees.\n",
      "    \"\"\"\n",
      "    if units=='pix':\n",
      "        vac=VisualAngleCalc(display_size_mm=(500.0,300.0),display_res_pix=(1280.0,1024.0),eye_distance_mm=550.0)\n",
      "        if data_y is None:\n",
      "            data_x=vac.pix2deg(data_x)\n",
      "        else:\n",
      "            data_x=vac.pix2deg(data_x)\n",
      "            data_y=vac.pix2deg(data_y)\n",
      "            data=np.sqrt(data_x*data_x+data_y*data_y)\n",
      "    else:\n",
      "        if data_y is None:\n",
      "            data=data_x\n",
      "        else:\n",
      "            data=np.sqrt(data_x*data_x+data_y*data_y)\n",
      "        \n",
      "    velocity_between = (data[1:]-data[:-1])/(time[1:]-time[:-1])\n",
      "    velocity = (velocity_between[1:]+velocity_between[:-1])/2.0\n",
      "    return velocity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# calculateAccelleration(time,data_x,data_y=None,units='deg')\n",
      "\n",
      "Calculate the instantanious calculateAccelleration for data points in data_x and (optionally) data_y, using the time array for time delta information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculateAccelleration(time,data_x,data_y=None,units='deg'):\n",
      "    \"\"\"\n",
      "    Returns data in visual degrees.\n",
      "    \"\"\"\n",
      "    velocity=calculateVelocity(time,data_x,data_y,units)\n",
      "    accel = calculateVelocity(time[1:-1],velocity)\n",
      "    return accel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}