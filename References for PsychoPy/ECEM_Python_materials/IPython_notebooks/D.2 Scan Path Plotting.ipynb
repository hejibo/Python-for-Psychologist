{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from executeNotebook import execute_notebook\n",
      "execute_notebook(\"Py4ET_2013_ECEM_Workshop.ipynb\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "#B. Scan Paths\n",
      "\n",
      "**Scan path overlay plots** are generally created using either:\n",
      "\n",
      "- the eye tracker sample stream to generate the line segements for the scan path ( **Sample Based Scan Paths** )\n",
      "- the fixation (and possibly saccade) event stream generated by the eye trackking softwares eye event parser ( **Fixation / Event Based Scan Paths** )\n",
      "\n",
      "When a scan path overlay is sample based, areas of increased dwell time can usually be seen as the clustering of sample line segments within areas of the scene.\n",
      "\n",
      "When an event based scan path is used, it is common for each fixation event to be plotted as a circle shape, often with each fixation circle diameter being \n",
      "scaled by the fixation event duration. Saccade events can be represented as lines joining the relevent surrounding fixation events, or fixations can simply \n",
      "be joined by lines anchored to each fixations center point, thereby not attempting to use any available saccadic information (angle, duration, etc.).\n",
      "\n",
      "The scan path overlays to follow are created using an eye sample based approach. \n",
      "\n",
      "To aid in the visualization of the temportal order of the sample scan trace, a color map is used, with the color ramp normalized to the start and end time\n",
      "of the sample data being plotted (the trial time). This is often a more effective way of relaying temporal information on the 2D scan path plot compared\n",
      "to cluttering the scan path with numbers giving the trial time of eveny Nth scan path segment, or the sample index, etc. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PLOT_SIZE=19,11\n",
      "plt.rcParams['figure.figsize']=PLOT_SIZE\n",
      "\n",
      "# For binocular recording 0 = Left eye, 1 = Right eye. Monocular recording should always use 0.\n",
      "#\n",
      "EYE_INDEX=0\n",
      "    \n",
      "# Select the ioDataStore hdf5 file to process.\n",
      "# and load specified event type and event attribute values.\n",
      "#\n",
      "results_by_trial=loadSampleData(ET_WORKBOOK_INFO['event_type'],\n",
      "                                         ET_WORKBOOK_INFO['event_fields'])\n",
      "\n",
      "# Process sample streams for plotting\n",
      "#\n",
      "gaze_field_groups=ET_WORKBOOK_INFO['gaze_fields']\n",
      "pupil_size_fields=ET_WORKBOOK_INFO['pupil_size_fields']\n",
      "\n",
      "for trial_data in results_by_trial:\n",
      "    invalid_data_masks=[]\n",
      "    if EYE_TRACKER_USED=='SRR':\n",
      "        invalid_data_masks.append(trial_data.pupil_measure1==0)\n",
      "        \n",
      "    elif EYE_TRACKER_USED=='TOBII':\n",
      "        invalid_data_masks.append(trial_data.status//10>=2)\n",
      "        invalid_data_masks.append(trial_data.status%10>=2)\n",
      "\n",
      "    # Create Image background for each trial scanpath\n",
      "    \n",
      "    # get the condition variable set used for the current trial\n",
      "    #\n",
      "    condition_set=trial_data.condition_set\n",
      "    \n",
      "    # Get the image name used for display during the trial\n",
      "    #\n",
      "    image_name=condition_set.IMAGE_NAME\n",
      "    trial_id=condition_set.trial_id\n",
      "    # load the image\n",
      "    #\n",
      "    trial_image_array=numpy.flipud(mpimg.imread(\"./images/\"+image_name))\n",
      "\n",
      "    # Get background image size\n",
      "    image_size=(trial_image_array.shape[1],trial_image_array.shape[0])\n",
      "    ihw,ihh=image_size[0]/2,image_size[1]/2\n",
      "\n",
      "    # Display image for illustrative purposes, 0,0 is image center.\n",
      "    #\n",
      "    plt.figure()\n",
      "    bip=plt.imshow(trial_image_array,origin='lower',extent=(-ihw, ihw,-ihh, ihh))\n",
      "    plt.title(\"Trial {0}: {1}\".format(trial_id,image_name))\n",
      "    \n",
      "    x,y=getattr(trial_data,gaze_field_groups[EYE_INDEX][0]).copy(),getattr(trial_data,gaze_field_groups[EYE_INDEX][1]).copy()\n",
      "    p=getattr(trial_data,pupil_size_fields[EYE_INDEX]).copy()\n",
      "    time=trial_data.time\n",
      "    \n",
      "    valid_data_periods=processSampleEventGaps(x,y,p,invalid_data_masks[EYE_INDEX],'clear')\n",
      "\n",
      "    sample_points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
      "    sample_segments = np.concatenate([sample_points[:-1], sample_points[1:]], axis=1)\n",
      "\n",
      "    scan_path_line_collection = LineCollection(sample_segments, cmap=plt.get_cmap('YlOrRd'),\n",
      "    norm=plt.Normalize(time.min(), time.max()))\n",
      "    scan_path_line_collection.set_array(time)\n",
      "    scan_path_line_collection.set_linewidth(2)\n",
      "\n",
      "    plt.gca().add_collection(scan_path_line_collection)\n",
      "    \n",
      "    cb=plt.colorbar(scan_path_line_collection)\n",
      "    cb.set_label(\"Trial Time (sec)\") \n",
      "\n",
      "    plt.show()\n",
      "    \n",
      "plt.rcdefaults()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}