{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Parsing Eye Events from Eye Samples using a Velocity Based Algorithm\n",
      "\n",
      "Here we will look at a Eye Events Parser. This is not a *suggested* parser, or the *best* parser, infact it may be a *crappy* parser. More testing from different eye trackers and data sets is needed before anything can be said about how well the following approach works. \n",
      "\n",
      "The example code *is* useful from the point of view of showing how one might go about trying to develop a parsing algorithm in python, including at least some of the steps that may be taken during such a research project. \n",
      "\n",
      "Notes:\n",
      "\n",
      "- Will handle monocular data.\n",
      "- Use a Velocity / Accelleration based Parsing Model.\n",
      "- Filter data streams as needed.\n",
      "- Use some heuristics to identify possible false alarms\n",
      "    \n",
      "    - Maximum Realistic Velocity and Accelleration values\n",
      "    - Peak Velocity Point within Saccade Candidates\n",
      "    - Minimum / Maximum Event Durations\n",
      "    - Others ??\n",
      "    \n",
      "- Focus on creating an off-line parser. An on-line version can be homework. ;)\n",
      "\n",
      "##I. Load some test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from executeNotebook import execute_notebook\n",
      "execute_notebook(\"Py4ET_2013_ECEM_Workshop.ipynb\")\n",
      "execute_notebook(\"Savitzky_Golay_Filter.ipynb\")\n",
      "\n",
      "# Select the ioDataStore hdf5 file to process.\n",
      "# and load specified event type and event attribute values.\n",
      "#\n",
      "multi_trial_sample_data=loadSampleData(ET_WORKBOOK_INFO['event_type'],\n",
      "                                         ET_WORKBOOK_INFO['event_fields'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##II. Create Various Flavours of the Data Streams to be Used, Handling Missing Data Gaps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Process sample streams\n",
      "#\n",
      "\n",
      "BINOC_EYE=0\n",
      "SPATIAL_FILTER_WINDOW_SIZE=5\n",
      "VELOCITY_FILTER_WINDOW_SIZE=5\n",
      "PLOT_SIZE=19,11\n",
      "\n",
      "gaze_field_groups=ET_WORKBOOK_INFO['gaze_fields']\n",
      "pupil_size_fields=ET_WORKBOOK_INFO['pupil_size_fields']\n",
      "\n",
      "def createTrialDataStreams():\n",
      "    trial_data_streams=[]\n",
      "    for t,trial_data in enumerate(multi_trial_sample_data):\n",
      "        #Create a mask to be used to define periods of missing data in a data trace (eye tracker dependent)\n",
      "        invalid_data_mask=None\n",
      "        if EYE_TRACKER_USED=='SRR':\n",
      "            invalid_data_mask=trial_data.pupil_measure1==0 # || getattr(trial_data,gaze_field_groups[BINOC_EYE][0])>1000 || getattr(trial_data,gaze_field_groups[BINOC_EYE][0])<1000 || getattr(trial_data,gaze_field_groups[BINOC_EYE][1])>1000 || getattr(trial_data,gaze_field_groups[BINOC_EYE][1])<1000 \n",
      "        elif EYE_TRACKER_USED=='TOBII':\n",
      "            if BINOC_EYE is 0:\n",
      "                invalid_data_mask=trial_data.status//10>=2\n",
      "            else:\n",
      "                invalid_data_mask=trial_data.status%10>=2\n",
      "        time=trial_data.time\n",
      "        pupil=getattr(trial_data,pupil_size_fields[BINOC_EYE])\n",
      "        # Get x, y eye position traces (in pixels), setting sample positions where there is track loss\n",
      "        # to NaN.\n",
      "        xpix_cleared=getattr(trial_data,gaze_field_groups[BINOC_EYE][0]).copy()\n",
      "        ypix_cleared=getattr(trial_data,gaze_field_groups[BINOC_EYE][1]).copy()\n",
      "        processSampleEventGaps(xpix_cleared,ypix_cleared,pupil,invalid_data_mask,'clear')\n",
      "    \n",
      "        # Get x, y eye position traces (in pixels), setting sample positions where there is track loss\n",
      "        # to be linearly interpolated using each missing_sample_start-1 and missing_sample_end+1 as the points to\n",
      "        # interpolate between.\n",
      "        xpix_linear=getattr(trial_data,gaze_field_groups[BINOC_EYE][0]).copy()\n",
      "        ypix_linear=getattr(trial_data,gaze_field_groups[BINOC_EYE][1]).copy()\n",
      "    \n",
      "        # valid_data_periods is a list of array slice objects giving the start,end index of each non missing \n",
      "        # period of in the data stream.\n",
      "        valid_data_periods=processSampleEventGaps(xpix_linear,ypix_linear,pupil,invalid_data_mask,'linear')\n",
      "     \n",
      "        # Convert from pixels to visual angle coordinates\n",
      "        calibration_area_info=ET_WORKBOOK_INFO['calibration_area_info']\n",
      "        vac=VisualAngleCalc(**calibration_area_info)      \n",
      "        xdeg,ydeg=vac.pix2deg(xpix_linear,ypix_linear)\n",
      "    \n",
      "        # Create Filtered versions of the x and y degree data traces\n",
      "        # We'll try using the Median Filter...\n",
      "        xdeg_filtered = scipy.signal.medfilt(xdeg,SPATIAL_FILTER_WINDOW_SIZE)\n",
      "        ydeg_filtered = scipy.signal.medfilt(ydeg,SPATIAL_FILTER_WINDOW_SIZE)\n",
      "        \n",
      "        # Create the velocity stream\n",
      "        xvel=calculateVelocity(time,xdeg_filtered)\n",
      "        yvel=calculateVelocity(time,ydeg_filtered)\n",
      "\n",
      "        FILTER_ORDER=2\n",
      "        Wn=0.3#((ET_SAMPLING_HZ/2.0)*(NYQUIST_FREQ_PERC*0.01))/ET_SAMPLING_HZ\n",
      "        b, a = scipy.signal.butter(FILTER_ORDER, Wn, 'low')\n",
      "        ffunc=scipy.signal.filtfilt\n",
      "        xvel_filtered = ffunc(b, a, xvel)\n",
      "        yvel_filtered = ffunc(b, a, yvel)\n",
      "\n",
      "#        xvel_filtered=savitzky_golay(xvel,window_size=VELOCITY_FILTER_WINDOW_SIZE,order=2)\n",
      "#        yvel_filtered=savitzky_golay(yvel,window_size=VELOCITY_FILTER_WINDOW_SIZE,order=2)\n",
      "#        xvel_filtered=gaussian_filter1d(xvel,VELOCITY_FILTER_WINDOW_SIZE)\n",
      "#        yvel_filtered=gaussian_filter1d(yvel,VELOCITY_FILTER_WINDOW_SIZE)\n",
      "#        xvel_filtered=scipy.signal.medfilt(xvel,VELOCITY_FILTER_WINDOW_SIZE)\n",
      "#        yvel_filtered=scipy.signal.medfilt(yvel,VELOCITY_FILTER_WINDOW_SIZE)\n",
      "\n",
      "        velocity=np.sqrt(xvel*xvel+yvel*yvel)\n",
      "        #velocity_filtered=xvel_filtered=savitzky_golay(velocity,window_size=VELOCITY_FILTER_WINDOW_SIZE,order=2)\n",
      "        velocity_filtered=np.sqrt(xvel_filtered*xvel_filtered+yvel_filtered*yvel_filtered)\n",
      "    \n",
      "        # Create the accelleration stream\n",
      "        xacc=calculateAccelleration(time,xdeg_filtered)\n",
      "        yacc=calculateAccelleration(time,ydeg_filtered)\n",
      "        accelleration=np.sqrt(xacc*xacc+yacc*yacc)\n",
      "    \n",
      "        # Create a data trace dictionary for all the different types\n",
      "        #  of data traces created for the trial\n",
      "        #\n",
      "        trial_data={}\n",
      "        trial_data['time']=time\n",
      "        trial_data['xpix_cleared']=xpix_cleared\n",
      "        trial_data['ypix_cleared']=ypix_cleared\n",
      "        trial_data['xpix_linear']=xpix_linear\n",
      "        trial_data['xpix_linear']=xpix_linear\n",
      "        trial_data['xdeg']=xdeg\n",
      "        trial_data['ydeg']=ydeg\n",
      "        trial_data['xdeg_filtered']=xdeg_filtered\n",
      "        trial_data['ydeg_filtered']=ydeg_filtered\n",
      "        trial_data['pupil']=pupil\n",
      "        trial_data['velocity']=velocity\n",
      "        trial_data['velocity_filtered']=velocity_filtered\n",
      "        trial_data['accelleration']=accelleration\n",
      "        trial_data['valid_data_periods']=valid_data_periods\n",
      "        trial_data['missing_data_mask']=invalid_data_mask\n",
      "        # Add the data trace dictionary to a list\n",
      "        #\n",
      "        trial_data_streams.append(trial_data)\n",
      "    return trial_data_streams\n",
      "\n",
      "def calculateVelocityThresholdPerTrial(trial_data_streams):\n",
      "    for t,trial_data in enumerate(trial_data_streams):        \n",
      "        pt_list=[]        \n",
      "        missing_data_mask=trial_data['missing_data_mask']\n",
      "        valid_velocity_filtered=trial_data['velocity_filtered'][~missing_data_mask[1:-1]]\n",
      "        PT=valid_velocity_filtered.min()+np.array(valid_velocity_filtered,dtype=float64).std()*3.0\n",
      "        velocity_below_thresh=valid_velocity_filtered[valid_velocity_filtered<PT]\n",
      "        PTd=2.0\n",
      "        while PTd >= 1.0:   \n",
      "            if len(pt_list)>0:\n",
      "                PT=velocity_below_thresh.mean()+3.0*np.array(velocity_below_thresh,dtype=float64).std()\n",
      "                velocity_below_thresh=valid_velocity_filtered[valid_velocity_filtered<PT]\n",
      "                PTd=np.abs(PT-pt_list[-1])\n",
      "            pt_list.append(PT)\n",
      "\n",
      "        saccade_candidate_mask=(trial_data['velocity_filtered']>=PT)\n",
      "        saccade_candidate_mask[missing_data_mask[1:-1]]=0\n",
      "        saccade_candidate_periods=np.ma.extras.notmasked_contiguous(\n",
      "                                np.ma.array(trial_data['velocity_filtered'],\n",
      "                                            mask=saccade_candidate_mask)\n",
      "                                )                                \n",
      "    \n",
      "        trial_data['velocity_threshold_points']=np.asarray(pt_list)\n",
      "        trial_data['saccade_candidate_mask']=saccade_candidate_mask\n",
      "        trial_data['saccade_candidate_periods']=saccade_candidate_periods\n",
      "\n",
      "trial_data_streams=createTrialDataStreams()\n",
      "calculateVelocityThresholdPerTrial(trial_data_streams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##III: Creating the Event Type Stream"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MISSING=1\n",
      "BLINK=2 # not yet used\n",
      "SACCADE=4\n",
      "FIXATION=8\n",
      "RINGING=16 # not used\n",
      "PURSUIT=32 # not used\n",
      "\n",
      "eye_event_status=np.zeros(trial_data_streams[0]['time'].shape,dtype=np.uint8)\n",
      "\n",
      "for t,trial_traces_dict in enumerate(trial_data_streams):\n",
      "    time=trial_traces_dict['time']\n",
      "    pupil=trial_traces_dict['pupil']\n",
      "    xdeg=trial_traces_dict['xdeg']\n",
      "    ydeg=trial_traces_dict['ydeg']\n",
      "    xdeg_filtered=trial_traces_dict['xdeg_filtered']\n",
      "    ydeg_filtered=trial_traces_dict['ydeg_filtered']\n",
      "    velocity=trial_traces_dict['velocity']\n",
      "    velocity_filtered=trial_traces_dict['velocity_filtered']\n",
      "    missing_data_mask=trial_traces_dict['missing_data_mask']\n",
      "    valid_data_periods=trial_traces_dict['valid_data_periods']\n",
      "    saccade_candidate_mask=trial_traces_dict['saccade_candidate_mask']\n",
      "    saccade_candidate_periods=trial_traces_dict['saccade_candidate_periods']\n",
      "    \n",
      "    # Create event event status stream. \n",
      "    # Currently only tags missing data periods, saccades, \n",
      "    # and fills in the rest a Fixaions. \n",
      "    # This can be improved to distinguish between missing data \n",
      "    # periods that are likely from a blink, \n",
      "    # vs. other eye signal loss reason. Further more, it would be nice to \n",
      "    # determine periods of smooth persuite from the currently tagged Fixation\n",
      "    # regions when possible.\n",
      "    #\n",
      "    eye_event_status[missing_data_mask]+=MISSING\n",
      "    eye_event_status[saccade_candidate_mask]+=SACCADE\n",
      "    eye_event_status[eye_event_status==0]+=FIXATION\n",
      "    \n",
      "    trial_traces_dict['eye_event_status']=eye_event_status"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##IV. Plot the Traces Created"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize']=PLOT_SIZE\n",
      "\n",
      "\n",
      "deg_pos_colors=((0.,.25,0.),(0.,.75,0.),(0.,0.,.25),(0.,0.,.25),(0.,0.,0.))\n",
      "velocity_colors=((.25,0.,0.),(.75,0.,0.),(.5,0.,0.))\n",
      "event_bar_colors=dict(saccade=(0.,1.,0.),fixation=(1.,0.,0.),missing=(0,0,0))\n",
      "\n",
      "for t,trial_traces_dict in enumerate(trial_data_streams):\n",
      "    time=trial_traces_dict['time']\n",
      "    pupil=trial_traces_dict['pupil']\n",
      "    xdeg=trial_traces_dict['xdeg']\n",
      "    ydeg=trial_traces_dict['ydeg']\n",
      "    xdeg_filtered=trial_traces_dict['xdeg_filtered']\n",
      "    ydeg_filtered=trial_traces_dict['ydeg_filtered']\n",
      "    velocity=trial_traces_dict['velocity']\n",
      "    velocity_filtered=trial_traces_dict['velocity_filtered']\n",
      "    missing_data_mask=trial_traces_dict['missing_data_mask']\n",
      "    eye_event_status=trial_traces_dict['eye_event_status']\n",
      "    \n",
      "    fig = plt.figure('Trial %d'%(t+1))\n",
      "    fig.title=(\"Trial %d Eye Data Strip Chart\"%(t+1))\n",
      "\n",
      "    ax=plt.gca()\n",
      "    xdeg[missing_data_mask]=np.NaN\n",
      "    ydeg[missing_data_mask]=np.NaN\n",
      "    #ax.plot(time,xdeg,label='Horz. Pos. (Degrees)',color=deg_pos_colors[0])\n",
      "    #ax.plot(time,ydeg,label='Vert. Pos. (Degrees)',color=deg_pos_colors[2])\n",
      "    xdeg_filtered[missing_data_mask]=np.NaN\n",
      "    ydeg_filtered[missing_data_mask]=np.NaN\n",
      "    ax.plot(time,xdeg_filtered,label='Filtered Horz. Pos. (Degrees)',color=deg_pos_colors[1])\n",
      "    ax.plot(time,ydeg_filtered,label='Filtered Vert. Pos. (Degrees)',color=deg_pos_colors[3])\n",
      "\n",
      "    tmin=time.min()//1\n",
      "    tmax=time.max()//1+1\n",
      "    plt.xticks(np.arange(tmin,tmax,0.5),rotation='vertical')\n",
      "    trans = mtransforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
      "    \n",
      "    # Missing data vertical bars\n",
      "    ax.fill_between(time, 0, 1, where=pupil==0, facecolor=(.2,.2,.2), edgecolor=(.2,.2,.2),\n",
      "                    alpha=0.5, transform=trans)\n",
      "\n",
      "\n",
      "    # Saccade Canditates vertical bars\n",
      "    ax.fill_between(time[1:-1], 0, 1, \n",
      "                    where=trial_traces_dict['velocity_filtered']>=trial_traces_dict['velocity_threshold_points'][-1],\n",
      "                    facecolor=(.5,0,.5), edgecolor=(.5,0,.5),\n",
      "                    alpha=0.5, transform=trans)\n",
      "\n",
      "    ax.set_xlabel('Time')\n",
      "    ax.set_ylabel('Position (Degrees)',color=deg_pos_colors[-1])\n",
      "    for tl in ax.get_yticklabels():\n",
      "        tl.set_color(deg_pos_colors[-1])\n",
      "    \n",
      "    ax2 = ax.twinx()\n",
      "    velocity[missing_data_mask[1:-1]]=np.NaN\n",
      "    velocity_filtered[missing_data_mask[1:-1]]=np.NaN\n",
      "    #ax2.plot(time[1:-1],velocity,label='XY Velocity',color=velocity_colors[0])\n",
      "    ax2.plot(time[1:-1],velocity_filtered,label='Filtered XY Velocity',color=velocity_colors[1])\n",
      "    ax2.set_ylabel('Velocity (degrees / second)',color=velocity_colors[-1])\n",
      "    for tl in ax2.get_yticklabels():\n",
      "        tl.set_color(velocity_colors[-1])\n",
      "\n",
      "    plt.axhline(y=trial_traces_dict['velocity_threshold_points'][0],color='g')\n",
      "    plt.axhline(y=trial_traces_dict['velocity_threshold_points'][-1],color='r')\n",
      "\n",
      "    handles, labels = ax.get_legend_handles_labels()\n",
      "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
      "    handles.extend(handles2)\n",
      "    labels.extend(labels2)\n",
      "    legend(handles,labels,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.) #plt.legend(loc=(1.01,.8))        \n",
      "\n",
      "    plt.grid()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##X: Future Enhancements\n",
      "\n",
      "- Perform a dilated / erosion process on the missing data gaps so fill in gaps which occur within close temporal proximity to each other.\n",
      "- Expand the missing data gaps to factor in the *artificial saccade* effect that often surrounds a missing data gap period.\n",
      "- Consider using Acceleration data as another saccade variable.\n",
      "- The current saccade detection really only finds the saccadic periods in a first pass type fashion. A second stage could be applied that uses the peak velocity within a saccadic period and walks back and forward to enhance the start and end of the saccadic sample period.\n",
      "- Use rate of pupil size change as another measure to help detect high velocities based on eye signal degradation and not true eye positional movement.\n",
      "- Have min / max Velocity and Acceleration cutoffs to remove not biologically plausible rates of eye movement.\n",
      "- Remove any eye positions reported to be 2x ( exact number  TBD) the width or height of the calibration area.\n",
      "- Develop a parsing implementation that can be used online as data is being collected.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}